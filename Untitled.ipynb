{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------- CNN ------------------------\n",
    "from utils.hparams import HParams\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "from crf_model import CRF\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self,config):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.timestep = config['timestep']\n",
    "        self.context = 7\n",
    "        self.pad = nn.ConstantPad1d(self.context, 0)\n",
    "        self.probs_out = config['probs_out']\n",
    "        self.num_chords = config['num_chords']\n",
    "\n",
    "        self.drop_out = nn.Dropout2d(p=0.5)\n",
    "        self.conv1 = self.cnn_layers(1, 32, kernel_size=(3,3), padding=1)\n",
    "        self.conv2 = self.cnn_layers(32, 32, kernel_size=(3,3), padding=1)\n",
    "        self.conv3 = self.cnn_layers(32, 32, kernel_size=(3,3), padding=1)\n",
    "        self.conv4 = self.cnn_layers(32, 32, kernel_size=(3,3), padding=1)\n",
    "        self.pool_max = nn.MaxPool2d(kernel_size=(2,1))\n",
    "        self.conv5 = self.cnn_layers(32, 64, kernel_size=(3, 3), padding=0)\n",
    "        self.conv6 = self.cnn_layers(64, 64, kernel_size=(3, 3), padding=0)\n",
    "        self.conv7 = self.cnn_layers(64, 128, kernel_size=(12, 9), padding=0)\n",
    "        self.conv_linear = nn.Conv2d(128, config['num_chords'], kernel_size=(1,1), padding=0)\n",
    "\n",
    "    def cnn_layers(self, in_channels, out_channels, kernel_size, stride=1, padding=0):\n",
    "        layers = []\n",
    "        conv2d = nn.Conv2d(in_channels, out_channels,kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "        batch_norm = nn.BatchNorm2d(out_channels)\n",
    "        relu = nn.ReLU(inplace=True)\n",
    "        layers += [conv2d, batch_norm, relu]\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    #def forward(self, x, labels):\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0,2,1)\n",
    "        x = self.pad(x)\n",
    "        batch_size = x.size(0)\n",
    "        for i in range(batch_size):\n",
    "            for j in range(self.timestep):\n",
    "                if i == 0 and j == 0:\n",
    "                    inputs = x[i,:,j : j + self.context *2 + 1].unsqueeze(0)\n",
    "                else:\n",
    "                    tmp = x[i, :, j : j + self.context *2 + 1].unsqueeze(0)\n",
    "                    inputs = torch.cat((inputs,tmp), dim=0)\n",
    "        # inputs : [batchsize * timestep, feature_size, context]\n",
    "        inputs = inputs.unsqueeze(1)\n",
    "        conv = self.conv1(inputs)\n",
    "        conv = self.conv2(conv)\n",
    "        conv = self.conv3(conv)\n",
    "        conv = self.conv4(conv)\n",
    "        pooled = self.pool_max(conv)\n",
    "        pooled = self.drop_out(pooled)\n",
    "        conv = self.conv5(pooled)\n",
    "        conv = self.conv6(conv)\n",
    "        pooled = self.pool_max(conv)\n",
    "        pooled = self.drop_out(pooled)\n",
    "        conv = self.conv7(pooled)\n",
    "        conv = self.drop_out(conv)\n",
    "        conv = self.conv_linear(conv)\n",
    "        avg_pool = nn.AvgPool2d(kernel_size=(conv.size(2), conv.size(3)))\n",
    "        logits = avg_pool(conv).squeeze(2).squeeze(2)\n",
    "        if self.probs_out is True:\n",
    "            crf_input = logits.view(-1, self.timestep, self.num_chords)\n",
    "            return crf_input\n",
    "        log_probs = F.log_softmax(logits, -1)\n",
    "        topk, indices = torch.topk(log_probs, 2)\n",
    "        predictions = indices[:,0]\n",
    "        second = indices[:,1]\n",
    "        prediction = predictions.view(-1)\n",
    "        second = second.view(-1)\n",
    "        #loss = F.nll_loss(log_probs.view(-1, self.num_chords), labels.view(-1))\n",
    "        #return prediction, loss, 0, second\n",
    "        return prediction\n",
    "\n",
    "class Crf(nn.Module):\n",
    "    def __init__(self, num_chords, timestep):\n",
    "        super(Crf, self).__init__()\n",
    "        self.output_size = num_chords\n",
    "        self.timestep = timestep\n",
    "        self.Crf = CRF(self.output_size)\n",
    "\n",
    "    #def forward(self, probs, labels):\n",
    "    def forward(self, probs):\n",
    "        prediction = self.Crf(probs)\n",
    "        prediction = prediction.view(-1)\n",
    "        #labels = labels.view(-1, self.timestep)\n",
    "        #loss = self.Crf.loss(probs, labels)\n",
    "        #return prediction, loss\n",
    "        return prediction\n",
    "\n",
    "\n",
    "class CRNN(nn.Module):\n",
    "    def __init__(self,config):\n",
    "        super(CRNN, self).__init__()\n",
    "\n",
    "        self.feature_size = config['feature_size']\n",
    "        self.timestep = config['timestep']\n",
    "        self.probs_out = config['probs_out']\n",
    "        self.num_chords = config['num_chords']\n",
    "        self.hidden_size = 128\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.batch_norm = nn.BatchNorm2d(1)\n",
    "        self.conv1 = nn.Conv2d(1, 1, kernel_size=(5,5), padding=2)\n",
    "        self.conv2 = nn.Conv2d(1, 36, kernel_size=(1,self.feature_size))\n",
    "        self.gru = nn.GRU(input_size=36, hidden_size=self.hidden_size, num_layers=2, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(self.hidden_size*2, self.num_chords)\n",
    "\n",
    "    def forward(self, x, labels):\n",
    "        # x : [batchsize * timestep * feature_size]\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.batch_norm(x)\n",
    "        conv = self.relu(self.conv1(x))\n",
    "        conv = self.relu(self.conv2(conv))\n",
    "        conv = conv.squeeze(3).permute(0,2,1)\n",
    "\n",
    "        h0 = torch.zeros(4, conv.size(0), self.hidden_size).to(torch.device(\"cuda\" if use_cuda else \"cpu\"))\n",
    "        gru, h = self.gru(conv, h0)\n",
    "        logits = self.fc(gru)\n",
    "        if self.probs_out is True:\n",
    "            # probs = F.softmax(logits, -1)\n",
    "            return logits\n",
    "        log_probs = F.log_softmax(logits, -1)\n",
    "        topk, indices = torch.topk(log_probs, 2)\n",
    "        predictions = indices[:,:,0]\n",
    "        second = indices[:,:,1]\n",
    "        prediction = predictions.view(-1)\n",
    "        second = second.view(-1)\n",
    "        loss = F.nll_loss(log_probs.view(-1, self.num_chords), labels.view(-1))\n",
    "        return prediction, loss, 0, second\n",
    "#---------------------  ------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/BTC-ISMIR19/utils/hparams.py:29: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  return cls(**yaml.load(f))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import mir_eval\n",
    "import pretty_midi as pm\n",
    "from utils import logger\n",
    "from btc_model import *\n",
    "from utils.mir_eval_modules import audio_file_to_features, idx2chord, idx2voca_chord, get_audio_paths\n",
    "import argparse\n",
    "import warnings\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "config = HParams.load(\"config/run_config_idx{}.yaml\".format(1))\n",
    "config.feature['large_voca'] = True\n",
    "config.model['num_chords'] = 170\n",
    "model = CNN(config=config.model).to(device)\n",
    "model_file = './data/assets/model/idx_2_010.pt'\n",
    "normal_file = './data/result/22050_10.0_5.0_cqt_144_24_2048_mix_kfold_3_index2.pt'\n",
    "\n",
    "idx_to_chord = idx2voca_chord()    \n",
    "checkpoint = torch.load(model_file)\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "\n",
    "checkpoint = torch.load(normal_file)\n",
    "mean = checkpoint['mean']\n",
    "std = checkpoint['std']\n",
    "logger.info(\"restore model\")\n",
    "\n",
    "# Audio files with format of wav and mp3\n",
    "audio_paths = get_audio_paths('./test/mp3/ce1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, audio_path in enumerate(audio_paths):\n",
    "    logger.info(\"======== %d of %d in progress ========\" % (i + 1, len(audio_paths)))\n",
    "    # Load mp3\n",
    "    feature, feature_per_second, song_length_second = audio_file_to_features(audio_path, config)\n",
    "    logger.info(\"audio file loaded and feature computation success : %s\" % audio_path)\n",
    "\n",
    "    # Majmin type chord recognition\n",
    "    feature = feature.T\n",
    "    feature = (feature - mean) / std\n",
    "    time_unit = feature_per_second\n",
    "    n_timestep = config.model['timestep']\n",
    "\n",
    "    num_pad = n_timestep - (feature.shape[0] % n_timestep)\n",
    "    feature = np.pad(feature, ((0, num_pad), (0, 0)), mode=\"constant\", constant_values=0)\n",
    "    num_instance = feature.shape[0] // n_timestep\n",
    "\n",
    "    start_time = 0.0\n",
    "    lines = []\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        feature = torch.tensor(feature, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "        for t in range(num_instance):\n",
    "            prediction = model(feature[:, n_timestep * t:n_timestep * (t + 1), :])\n",
    "            #prediction = crf(probs)\n",
    "\n",
    "            for i in range(n_timestep):\n",
    "                if t == 0 and i == 0:\n",
    "                    prev_chord = prediction[i].cpu().numpy().item()\n",
    "                    continue\n",
    "                if prediction[i].item() != prev_chord:\n",
    "                    lines.append(\n",
    "                        '%.3f %.3f %s\\n' % (start_time, time_unit * (n_timestep * t + i), idx_to_chord[prev_chord]))\n",
    "                    start_time = time_unit * (n_timestep * t + i)\n",
    "                    prev_chord = prediction[i].item()\n",
    "                if t == num_instance - 1 and i + num_pad == n_timestep:\n",
    "                    if start_time != time_unit * (n_timestep * t + i):\n",
    "                        lines.append('%.3f %.3f %s\\n' % (start_time, time_unit * (n_timestep * t + i), idx_to_chord[prev_chord]))\n",
    "                    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
